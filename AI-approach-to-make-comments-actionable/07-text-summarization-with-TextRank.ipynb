{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izX9AmXqZiHq"
   },
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBYG7LR5Syjw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/YouTube-Project/data-youtube-comments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WrNuG0ID3Zm"
   },
   "source": [
    "### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "B5i-tHNtT4c5",
    "outputId": "69c302a1-e7f6-4cc8-b1e1-c0352349fb67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>time</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simplilearn</td>\n",
       "      <td>Simplilearn</td>\n",
       "      <td>🔥 Enroll for FREE Machine Learning Course &amp;amp...</td>\n",
       "      <td>26-03-2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>10:21:58</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simplilearn</td>\n",
       "      <td>Garde Tanmay</td>\n",
       "      <td>can I please get the datasets my email is tanm...</td>\n",
       "      <td>20-06-2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>16:23:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simplilearn</td>\n",
       "      <td>Simplilearn</td>\n",
       "      <td>Hi, thanks for watching our video. We have sen...</td>\n",
       "      <td>20-06-2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>18:33:08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simplilearn</td>\n",
       "      <td>Nirbhay Kumar</td>\n",
       "      <td>Great video , May I request data set at reach2...</td>\n",
       "      <td>20-06-2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>09:22:56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Simplilearn</td>\n",
       "      <td>Simplilearn</td>\n",
       "      <td>Hi, thanks for watching our video. We have sen...</td>\n",
       "      <td>20-06-2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>18:33:13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel           name  ...      time likes\n",
       "0  Simplilearn    Simplilearn  ...  10:21:58     4\n",
       "1  Simplilearn   Garde Tanmay  ...  16:23:47     0\n",
       "2  Simplilearn    Simplilearn  ...  18:33:08     0\n",
       "3  Simplilearn  Nirbhay Kumar  ...  09:22:56     1\n",
       "4  Simplilearn    Simplilearn  ...  18:33:13     0\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDnCjJrPIivZ"
   },
   "outputs": [],
   "source": [
    "df = df[50000:51000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "ItAeYbAiI6vV",
    "outputId": "619a9b80-923c-41f4-d92c-e66cb6b1afcd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>time</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>deeplizard</td>\n",
       "      <td>deeplizard</td>\n",
       "      <td>I elaborate more on this in the corresponding ...</td>\n",
       "      <td>09-10-2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>12:55:12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>deeplizard</td>\n",
       "      <td>Laeeq Khan</td>\n",
       "      <td>cooooooooooooooooooooooooooooool</td>\n",
       "      <td>03-10-2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>06:51:34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50002</th>\n",
       "      <td>deeplizard</td>\n",
       "      <td>Michael Marzolf</td>\n",
       "      <td>I have seen many explanations -- yours is the ...</td>\n",
       "      <td>02-10-2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>21:15:23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50003</th>\n",
       "      <td>deeplizard</td>\n",
       "      <td>Akshit Bhalla</td>\n",
       "      <td>Subscribed in 2min.</td>\n",
       "      <td>01-10-2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>17:21:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50004</th>\n",
       "      <td>deeplizard</td>\n",
       "      <td>Cheah Aun Mao</td>\n",
       "      <td>Hi, may I know the function of different type ...</td>\n",
       "      <td>01-10-2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>16:37:50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          channel             name  ...      time likes\n",
       "50000  deeplizard       deeplizard  ...  12:55:12     0\n",
       "50001  deeplizard       Laeeq Khan  ...  06:51:34     1\n",
       "50002  deeplizard  Michael Marzolf  ...  21:15:23     3\n",
       "50003  deeplizard    Akshit Bhalla  ...  17:21:00     1\n",
       "50004  deeplizard    Cheah Aun Mao  ...  16:37:50     0\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eWD1WMwD7vO"
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ew75XGMTWxDL",
    "outputId": "50f83f67-0528-49da-a860-a98ec34f6661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt') # one time execution\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "3CmvJ0gbW0eb",
    "outputId": "00840d46-76af-43b4-abb5-745fb406b03d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I elaborate more on this in the corresponding blog in the section &quot;a note about the usage of the dot product&quot;:<br><a href=\"https://deeplizard.com/learn/video/YRhxdVk_sIs\">https://deeplizard.com/learn/video/YRhxdVk_sIs</a>'"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "JY0c5E-DW0ja",
    "outputId": "f7f8ea44-46f0-4932-d982-85d5ab5d1cda"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'What&#39;s Python?'"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][50670]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhZ_bPBbEBc1"
   },
   "source": [
    "### Split Text into Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kt6_m8IEW0m8"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = []\n",
    "for s in df['comment']:\n",
    "  sentences.append(sent_tokenize(s))\n",
    "\n",
    "sentences = [y for x in sentences for y in x] # flatten list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWMmpLSQW0n7",
    "outputId": "cc309535-de59-40f6-f200-5aa45efafb86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I elaborate more on this in the corresponding blog in the section &quot;a note about the usage of the dot product&quot;:<br><a href=\"https://deeplizard.com/learn/video/YRhxdVk_sIs\">https://deeplizard.com/learn/video/YRhxdVk_sIs</a>',\n",
       " 'cooooooooooooooooooooooooooooool',\n",
       " 'I have seen many explanations -- yours is the best yet -- thank you<br><br><br>mike',\n",
       " 'Subscribed in 2min.',\n",
       " 'Hi, may I know the function of different type of multiplier accumulator (MAC) unit contribute to accelerate the process of DSP?',\n",
       " 'Perfect explanation as usual.',\n",
       " 'Pictures not words ;).',\n",
       " 'Nice!',\n",
       " '!',\n",
       " 'Very helpful.']"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IT6wuSHEHVX"
   },
   "source": [
    "### Download GloVe Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pH5xTPojW0sC",
    "outputId": "caaa7823-9899-43ad-c0ba-9cc18bb1e2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-10 17:39:55--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-08-10 17:39:55--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-08-10 17:39:55--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip.1’\n",
      "\n",
      "glove.6B.zip.1      100%[===================>] 822.24M  5.06MB/s    in 2m 40s  \n",
      "\n",
      "2021-08-10 17:42:35 (5.15 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove.6B.zip\n",
      "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: glove.6B.50d.txt        \n",
      "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: glove.6B.100d.txt       \n",
      "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: glove.6B.200d.txt       \n",
      "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQgY4oMtX0zu"
   },
   "outputs": [],
   "source": [
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtAoxQzdX02B",
    "outputId": "c2f60119-b210-4634-e765-9bb3d164004f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJCulkT3ERnQ"
   },
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q19bL5B7X04c"
   },
   "outputs": [],
   "source": [
    "# remove punctuations, numbers and special characters\n",
    "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "# make alphabets lowercase\n",
    "clean_sentences = [s.lower() for s in clean_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeGb3YVIEWoO"
   },
   "source": [
    "#### Import the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmfZ_FLOYAy1",
    "outputId": "8c8a4d30-855c-4a20-e7d7-2ed62901338c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-879A_DyYA1u"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc1besKfEbUE"
   },
   "source": [
    "#### Function to remove stopwords from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uk_aW0Q7YA4E"
   },
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCf-yP7zYA63"
   },
   "outputs": [],
   "source": [
    "# remove stopwords from the sentences\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ps0IFUZCElkv"
   },
   "source": [
    "### Vector Representation of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QE8Q2NrX08Z"
   },
   "outputs": [],
   "source": [
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKVtZL6JX09p"
   },
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "  if len(i) != 0:\n",
    "    v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "  else:\n",
    "    v = np.zeros((100,))\n",
    "  sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLqzNPsDEp76"
   },
   "source": [
    "### Similarity Matrix Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmXBfdZRYKE8"
   },
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upBZESGiE6sX"
   },
   "source": [
    "#### Cosine Similarity to compute the similarity between a pair of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDzBdC20YKIK"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7rcZGn3FBgs"
   },
   "source": [
    "#### Initialize the matrix with cosine similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDwpJBydYKLC"
   },
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "  for j in range(len(sentences)):\n",
    "    if i != j:\n",
    "      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1YgSS6FFHH2"
   },
   "source": [
    "### Applying PageRank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5waj-88YPzy"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRFAYAmbFMCV"
   },
   "source": [
    "### Summary Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0FEUYb9YP3I"
   },
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ru8w637bYP6M",
    "outputId": "3e899b0a-d6b9-4ff6-a0b6-43e3af8e44a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, it was a great video with really good explanation and use of really good examples....<br>Can I know the inspiration behind the channel&#39;s name?\n",
      "Honestly, I believe that power point presentation of the code with graphic explanation like you did is far better than the actual video of a code running, and, us as &quot;students&quot; try to follow with the Instructor.\n",
      "Hope I can continue to be a member for a long time.<br>Actually this is the first online course I have seen which does not throw syntax at you randomly and ACTUALLY tells you why you are doing something.\n",
      "Since I see you message is new ...is had a question please ... once I found that this video is before 2 years is it still best to start with.\n",
      "im not trying to hate but just saying if you dont practice the code he teaches on your own you will forget pretty much everything, dont do what i did i learnt the hard way make sure  to always practice code after a tutorial and try to do some projects after you learn a group of things.<br>-Also you can use a website such as codewars to practice regularly<br>Good luck people, i just dont want anyone to do the same thing i did\n",
      "Get mind to quite, rest, try picture 300k year\n",
      "It must have been really hard to put the video together but let me tell you, you just did a great job.\n",
      "Really good course, Dr. Chuck explains the topics in an easy way, I starting to understand  some things in Python that I do like a robot without understand.\n",
      "Thank you,your explanation was intuitive.I just have a question:<br><br>I like to draw a lot,and I draw  using the bézier tool almost exclusively,and bézier functions are made with polinomial equations.Furthermore,I work with béziers with three ponts rather than four,so it means that all my drawing are collections of parabolas and straight lines,and I have a tendency to be picky with geometry and symmetry.With that knowledge,how could I cheat,i mean help,the CNN so that it learns to draw just like me a little bit faster,without just copying my drawings pixel-by pixel?Could I,for example,pick the first layer of neurons and already put filters for parabolas and lines?\n",
      "Like no changes of versions in python   stuff like this comes in mind and hesitated ..hopefully you answer me thanks ^^\n",
      "Like no changes of versions in python   stuff like this comes in mind and hesitated ..hopefully you answer me thanks ^^\n",
      "I wonder how does cnn acheives that?<br><br>I have seen a lot of your videos and you seem to be one of the rarest people who actually explains very effectively  and so I am asking this question even if it may sound silly.\n",
      "And this video gave me answers for each and every doubt i got.<br>thank you very much.\n",
      "Thank you very very much sir I really love the way u explain I’m 16 and I am doing computer science\n",
      "I really appreciate your hard work in making the video...although I am interested in java I hope this video will help who wanna learn phython\n",
      "I think this man is very good at teaching and explaining Python, much better than all the individuals I’ve come across so far.\n",
      "Halo,<br> I would like to know regarding flattening in deep learning, and also.........<br>I would like to know how to create a new image dataset ?.......whether we should concern about image resolution and other criteria while downloading and saving.....etc....\n",
      "I did manage to get to the bottom of it meantime - NZ&#39;s position allows such cleverness - weirdly I had watched a goodly portion of standford lecture series on CNN&#39;s and was left with the same mistaken impression/confusion - Although I&#39;m left now with the feeling that this regular simple feature recognition in early layers of CNN&#39;s is rather uncanny - I guess it&#39;s logically required or predictable but still - amazing darn things aren&#39;t they.\n",
      "I really thought that as he explained the slides he would go and do the same in atom aur idk the command prompt like he showed how to make a file and then open it and stuff but none of that was there.\n",
      "It is like learning python from Guido van Rossum <br>Thank u thank u so much <br>You&#39;re really best person I&#39;ve ever seen in my whole life\n",
      "Its awesome, use google to answer any questions u may get.\n",
      "Learning Python is something you would like to get in your skills, but you do not know where to start?\n",
      "I am not sure if I understand your question but if you installed Python two years ago than there is no need to update it as the changes are minor and not relevant for beginner videos.\n",
      "Didn&#39;t see all your production but yes it resembles a good and well organized intermediate course, yes.\n",
      "@Sarah Chenaa yes there are changing in python version but the main purpose of this video is make your fundamentals clear of python even you search python there are lot of videos and series even intermediate level in python also in freecodecamp but my suggestion is if you start with fundamental of python this video is for you.\n",
      "Hello, I am Spanish speaker and I will watch this video as many times as necessary, I am learning to speak English and I think this will help and reinforce my training as well as the programming.\n",
      "Good to see he has made his knowledge more widely available.\n",
      "It really helps understanding the concept<br>One of the best explanations of CNN on Youtube.\n",
      "When instead of using a file you decided to hardcode one big string, you should fix that as well since you no longer need to loop through lines, just words!\n",
      "I wish you could explain all the layers of a CNN like LeNet-5 in a similar way\n",
      "However when I find something by Dr. Chuck I know it will be quality content and I will learn and understand a lot.\n",
      "Hey Shehwar - Yes, you could probably use transfer learning for this.\n",
      "I have been understanding the majority of the lecture and I can understand how the code works although it&#39;&#39;s little bit confusing for me at some of the time.\n",
      "Its a bit impossible to get a one-to-one mapping between them.\n",
      "Is there a way to have online one on one with u?\n",
      "Thank you for all this hard work you put in sharing Python knowledge with us.\n",
      "I accelerated the video a little bit but learned new things almost from the beginning!\n",
      "<br>I am wondering however, how a circle identification would work; not to even mention dog identification.<br>Nice video!\n",
      "really learnt a lot and gained a lot in this field !keep doing the good the work and enlighten the students with coding aspects!n cheers bud\n",
      "I have completed this full course on coursera... and seeing Dr. Chuck here again makes me happy.. can&#39;t think of this course in this channel... it&#39;s too good guys.. go for it...\n",
      "I just wanted to say amazing work on the video.\n",
      "clicks = &#39; great video clear and simple &#39;.split()\n",
      "<br>i_like_this = &#39;👍&#39;.join(clicks) +&#39;👍&#39;\n",
      "<br>print(i_like_this*43000)\n",
      "Even after 3, 4 hours of lecture i can still easily understand what you are teaching just by looking what you are drawing and by the visualized version of codes.\n",
      "Instead, the filter would have random values at the start, and then the CNN could learn that the edge detector values are the optimal values for that given filter, for example.Through the training process, the filter values are gradually updated to converge onto optimal values as the CNN learns.<br><br>I have a video on weight initialization and a 5-part video series on backprop both later in this playlist if you&#39;re interested in getting any deeper into the details there.<br><a href=\"https://www.youtube.com/playlist?list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU\">https://www.youtube.com/playlist?list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU</a><br><br>Let me know if this helps clarify.\n",
      "You will need months or maybe years to make something that it actually is profitable, if you want just a random project taht you can customize just google it, there is lots of tutorails of how to do them\n",
      "I don&#39;t get how they work, because they don&#39;t seem like networks at all, just a looping operation really.\n",
      "I find there is so much like upity attitude amongst people that work on computers.\n",
      "The number of people who watched this video: 2 million<br>The number of people who actually learned Python from this video: literally zero.<br><br>You guys literally picked the worst possible teacher to run this course.\n",
      "Many thanks for talking the time to put this out.\n",
      "Good Tutorial, would it be great if you add bookmark for each topic so that we can easily jump between topics if we already knows.\n",
      "can&#39;t imagine how much time and effort it took to create this... well... huge thank you\n",
      "You can think of these values in the same way as you think of weights getting updated in a standard network.\n",
      "Always had a hard time trying to understand and visualize a CNN - this video really broke ground for in that regard\n",
      "The key does not match, suppose you wanted to write counts[word]=count.get(word, 0) +1<br><br>Otherwise Python does not recognize that you are trying to define the key and the value for the same key value pair.\n",
      "I found this video very useful for me as a student in university of computer science , thanks a lot for sharing your experience and your knowledge with us for free, and thanks again to this wonderful channel .\n",
      "I&#39;m reminded when I was still a Computer Engineer at Control Data,, that was way back in 1984, Thank you for teaching us Python.\n",
      ":O<br>Great video tho, really helped to clarify things\n",
      "I don’t know hardly anything about computers, like many my age, 51, but have the desire and capacity to learn this language.\n",
      "Your teaching is so interesting, I know I will get better at programming.\n",
      "Hey, Can anybody guide on how to replace Tab with space in windows 10?<br> Being a commerce student and HR as my major in MBA, it&#39;s little difficult to understand!\n",
      "on <a href=\"https://www.youtube.com/watch?v=8DvywoWv6fI&amp;t=4h48m08s\">4:48:08</a> in the input(&#39;enter the line of text&#39;) , do you place the whole sentence or maybe the whole paragraph in the input function?<br><br>I don&#39;t know how to code but im trying to learn with this video lol\n",
      "SIR LOVE YOUR HARD WORK FOR THE BEST AND DETAILED VIDEO AND LOVE YOU FRO INDIA\n",
      "In the Keras series, I show a simple implementation of a CNN (without using a pre-trained model).<br>However, there is no straight forward answer for what type of exact infrastructure you should use.\n",
      "After watching this video will I be able to make my first project?<br>Course now I&#39;m like 9 hours ahead to be finishing it!!\n",
      "a very good way of teaching, but one thing you must add  is &quot;subtitles&quot;, it will help us understand it more accurately\n",
      "Nobody:<br>People in comment section: I am Old and I am learning Python Please Show me some Sympathy\n",
      "At first I was a bit discouraged by the length of the video but then after deciding to &quot;check out at least the beginning&quot; I ended up watching 1h30+ without realizing!!\n",
      "@goofy boomer YES That is the whole point, if you give an AI a large enough data set it should be able to interpret alien languages too simply by observing the syntax and &quot;learning&quot;\n",
      "Thought you might like to know there is a way how to add them.\n",
      "?<br>Like what is the user enters -1?<br>Wouldn&#39;t that trigger the &quot;except&quot; part of your code and return the &#39;Not a number&#39; message even though technically the user is entering a numb.\n",
      "I like the way you explained it.\n",
      "I really like the way you explain.\n",
      "Thanks for your answer, that&#39;s make more sense.\n",
      "I had never seen such a concise yet well-explained video on CNN before.\n",
      "Could you please let me know what graphic design software you use to draw your NN diagrams?\n",
      "I like the way you used illustrations to explain the idea behind.\n",
      "I understood the concept very clearly...Thank u so much for this video...\n",
      "I tried the code &quot;counting word frequency using dictionaries&quot;..I dont seem to get the correct output..:(..Instead of reading a file,,I randomly typed in a paragraph..and tried retrieving the most frequently used...There is no error in the program,,..but the output seems to be incorrect...can u pls help..<br>name = &quot;Python was created in the late 1980s, and first released in 1991, by Guido van Rossum as a successor to the ABC programming language.\n",
      "In any Folder navigate to View &gt; (In the section Show/Hide) mark a tick box that says &quot;File name extensions&quot;<br><br>Hope it helps and thank you for teaching us Python.\n",
      "really like the time when he pull out those hardware stuff.\n",
      "An excellent teacher and a great course.<br>Already &#39;did&#39; try a course on Udemy and it is at least 10 times better than that course.<br>Joined to show my appreciation.\n",
      "Please add a subtitle, some people like me, English listening is poor.\n",
      "You made it fun and though I struggled initially to understand all of  the concepts, I am at a stage where I can agree that programming is a life saver.\n",
      "I want to switch my career from account to IT industry <br>Which program should I learn to get into entry job In this field easily and how long do I have to study it?\n",
      "Seems like everyone agrees, that Excel example was on point!\n",
      "It just gets frustrating, for example, when I look for a tutorial about using Atom and their information assumes I know how to program already and teaches based on that assumption.\n",
      "But no other words are needed here except for great work :)\n",
      "That was a great video but I would like if you explained the other layers Pooling , fully connected ..\n",
      "I&#39;m looking at the comments mind blown by how much people that love this like...&quot;yall really watched this for almost 14 hours?&quot;...I must watch!\n",
      "So for those cases I&#39;m trying to write my own code following the same logic, but without necessarily doing everything the way he is doing.\n",
      "14 hours video that may be the longest youTube Video I&#39;ve ever seen in my life and what&#39;s more excited is that I&#39;ve decided to watch it all to learn python.\n",
      "Wow there’s so much to unravel here, thank you for taking the time to teach us.\n",
      "If I already know the basics of programming, where should I start this video ?\n",
      "Great video, thanks very much.\n",
      "Thank you so much for this video.\n",
      "This one is crystal clear and gives exactly the information we need at exactly the right pace and detail resolution.\n",
      "If anyone reads this and knows of a tutorial or anything that can teach an infant how to use an editor for computer programming please let me know.\n",
      "!There&#39;s one thing that I am not clear...As u explained 1 filter will detect one pattern(like edge) in the picture..Now to detect a image suppose a rat we need more than 1 filter...so how to know how many filters  we need to detect a image correctly...\n",
      "As someone said, all good acts will return to you with something better.\n",
      "It is usually not very easy to imagine all this without the help of visual material.\n"
     ]
    }
   ],
   "source": [
    "# Extract top 10 sentences as the summary\n",
    "for i in range(100):\n",
    "  print(ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oA2CV0sYP8n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtm50wopc6Ga"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "07. capstone-youtube-text-summarization-with-TextRank",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
